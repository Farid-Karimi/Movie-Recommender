{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce638f4",
   "metadata": {},
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d80f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded and merged.\n",
      "Shape of merged dataframe: (45453, 41)\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "movies_df = pd.read_csv('../Data/NewMoviesMetadata.csv', low_memory=False)\n",
    "credits_df = pd.read_csv('../Data/NewCredits.csv')\n",
    "keywords_df = pd.read_csv('../Data/NewKeywords.csv')\n",
    "\n",
    "# Ensure IDs are integers for a clean merge\n",
    "credits_df['id'] = credits_df['id'].astype(int)\n",
    "keywords_df['id'] = keywords_df['id'].astype(int)\n",
    "movies_df['id'] = movies_df['id'].astype(int)\n",
    "\n",
    "# Merge the dataframes into one\n",
    "merged_df = movies_df.merge(credits_df, on='id')\n",
    "merged_df = merged_df.merge(keywords_df, on='id')\n",
    "\n",
    "print(\"Data successfully loaded and merged.\")\n",
    "print(f\"Shape of merged dataframe: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f00870ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director(row):\n",
    "    \"\"\"\n",
    "    Parses crew data to find and return the director's name.\n",
    "    \"\"\"\n",
    "    # Handle missing or invalid crew data\n",
    "    if pd.isna(row['job_crew']) or pd.isna(row['name_crew']):\n",
    "        return np.nan\n",
    "        \n",
    "    # Create lists of jobs and names\n",
    "    jobs = row['job_crew'].split(', ')\n",
    "    names = row['name_crew'].split(', ')\n",
    "    \n",
    "    # Find the index of 'Director' and return the corresponding name\n",
    "    if 'Director' in jobs:\n",
    "        director_index = jobs.index('Director')\n",
    "        return names[director_index]\n",
    "    return np.nan\n",
    "\n",
    "# Apply the function to create the 'director' column\n",
    "merged_df['director'] = merged_df.apply(get_director, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a634ee5a",
   "metadata": {},
   "source": [
    "### Processing Text Features\n",
    "For the recommender, we'll combine several text-based features: genres, keywords, top cast members, and the director. To make these features useful, we need to clean and standardize them.\n",
    "\n",
    "The steps are:\n",
    "\n",
    "- Filter keywords: Keep only keywords that appear more than once to remove noise.\n",
    "\n",
    "- Stem keywords: Reduce words to their root form (e.g., \"jealousy\" becomes \"jealousi\").\n",
    "\n",
    "- Process all features: Convert all names and terms to lowercase and remove spaces to create unique tokens (e.g., \"Tom Hanks\" becomes \"tomhanks\").\n",
    "\n",
    "- Combine features: Aggregate all processed text into a single string for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3085cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Keyword Processing ---\n",
    "# Count all keyword occurrences to find common ones\n",
    "all_keywords = merged_df['name_keywords'].dropna().str.split(', ').explode()\n",
    "keyword_counts = all_keywords.value_counts()\n",
    "common_keywords = keyword_counts[keyword_counts > 1].index.tolist()\n",
    "\n",
    "# Function to filter, stem, and clean keywords\n",
    "stemmer = SnowballStemmer('english')\n",
    "def process_keywords(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    keywords = text.split(', ')\n",
    "    stemmed_keywords = [stemmer.stem(kw) for kw in keywords if kw in common_keywords]\n",
    "    return [kw.lower().replace(' ', '') for kw in stemmed_keywords]\n",
    "\n",
    "merged_df['keywords_processed'] = merged_df['name_keywords'].apply(process_keywords)\n",
    "\n",
    "\n",
    "# --- Cast, Genre, and Director Processing ---\n",
    "# Helper function to clean and limit the number of list items\n",
    "def clean_and_limit(text, limit=3):\n",
    "    if pd.isna(text) or text == '[]':\n",
    "        return []\n",
    "    items = text.split(', ')[:limit]\n",
    "    return [item.lower().replace(' ', '') for item in items]\n",
    "\n",
    "# Apply cleaning to other features\n",
    "merged_df['cast_processed'] = merged_df['name_cast'].apply(clean_and_limit, limit=5) # Take top 5 actors\n",
    "merged_df['genres_processed'] = merged_df['name_genres'].apply(clean_and_limit, limit=5)\n",
    "merged_df['director_processed'] = merged_df['director'].astype(str).apply(lambda x: [x.lower().replace(' ', '')] if x != 'nan' else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0463f9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 'model_feature' column created. Here's a sample:\n",
      "                         title  \\\n",
      "0                    Toy Story   \n",
      "1                      Jumanji   \n",
      "2             Grumpier Old Men   \n",
      "3            Waiting to Exhale   \n",
      "4  Father of the Bride Part II   \n",
      "\n",
      "                                       model_feature  \n",
      "0  jealousi toy boy friendship friend rivalri boy...  \n",
      "1  boardgam disappear basedonchildren'sbook newho...  \n",
      "2  fish bestfriend duringcreditssting oldmen walt...  \n",
      "3  basedonnovel interracialrelationship singlemot...  \n",
      "4  babi midlifecrisi confid age daughter motherda...  \n"
     ]
    }
   ],
   "source": [
    "# Combine all processed feature lists into one\n",
    "def create_feature_soup(row):\n",
    "    return ' '.join(row['keywords_processed'] + row['cast_processed'] + row['genres_processed'] + row['director_processed'])\n",
    "\n",
    "merged_df['model_feature'] = merged_df.apply(create_feature_soup, axis=1)\n",
    "\n",
    "print(\"Final 'model_feature' column created. Here's a sample:\")\n",
    "print(merged_df[['title', 'model_feature']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee97a9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommender data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Select and save the final data needed for the recommender\n",
    "recommender_data = merged_df[['id', 'title', 'model_feature']]\n",
    "recommender_data.to_csv('../data/MovieBasedRecommenderData.csv', index=False)\n",
    "\n",
    "print(\"\\nRecommender data saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
